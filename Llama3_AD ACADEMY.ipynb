{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# META LLAMA 3  \n","\n","# by ---  \"AD ACADEMY\" - AI for Aam Janta\n","\n","Mentor - Dr Ayan Debnath, IIT Delhi + Harvard university Alumni\n","\n","LinkedIn: [dr_ayan_debnath](https://www.linkedin.com/in/ayan-debnath/)\n","\n","YouTube:[AD ACADEMY AI](https://www.youtube.com/@ad_academy)\n","\n","Topic: Llama 3 implementation using Hugging Face\n","\n","class on 22nd April 2024"],"metadata":{"id":"dsRLwJE16tSD"}},{"cell_type":"markdown","source":["# Steps:\n","\n","\n","\n","1.   Importing Hugging Face library\n","2.   Using / build Pipeline to call LLM\n","3.   Generate text\n"],"metadata":{"id":"fxr2Dua6VX95"}},{"cell_type":"markdown","source":["# install Python packages"],"metadata":{"id":"MC3ruMhpVlUk"}},{"cell_type":"code","source":["# !pip install huggingfacehub\n","!pip install transformers\n","!pip install accelerate\n","!pip install torch"],"metadata":{"id":"pRk4Sl6Z65QX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Import Libraries"],"metadata":{"id":"6nPxxDMtVnkG"}},{"cell_type":"code","source":["import os\n","from transformers import pipeline\n","import torch"],"metadata":{"id":"mm47wlA3a9_8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Access Token\n","\n","check my YouTube video to know the steps"],"metadata":{"id":"ZjrSmxv5HZ0M"}},{"cell_type":"markdown","source":["# Model pipeline Building"],"metadata":{"id":"uphNtQKeHg9R"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"s8C-As7O6sRi"},"outputs":[],"source":["model_id = \"meta-llama/Meta-Llama-3-8B\"\n","\n","llm_model = pipeline(\n","    \"text-generation\", model=model_id, model_kwargs={\"torch_dtype\": torch.bfloat16}, device_map=\"auto\"\n",")\n","llm_model(\"Hey how are you doing today?\")"]},{"cell_type":"code","source":["llm_model(\"Hey tell me about Sachin tendulkar\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T0mAaYwr60cm","outputId":"7fe9687f-1109-4929-f0c5-b17cce59205d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"execute_result","data":{"text/plain":["[{'generated_text': 'Hey tell me about Sachin tendulkar, he is a great player, but he is not'}]"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["### download Original checkpoints"],"metadata":{"id":"Hzf11sqZUhBh"}},{"cell_type":"code","source":["huggingface-cli download meta-llama/Meta-Llama-3-8B --include \"original/*\" --local-dir Meta-Llama-3-8B\n"],"metadata":{"id":"GJdttrUoUfFG"},"execution_count":null,"outputs":[]}]}